<!DOCTYPE html>
<html lang="fa">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>تشخیص اعضای بدن و حذف پس‌زمینه</title>
    <script src="https://cdn.jsdelivr.net/npm/@mediapipe/pose"></script>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs-core"></script>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs-converter"></script>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs-backend-webgl"></script>
    <style>
        body {
            text-align: center;
            font-family: Arial, sans-serif;
        }
        video, canvas {
            width: 100%;
            max-width: 400px;
            border: 2px solid black;
        }
    </style>
</head>
<body>
    <h2>تشخیص بدن و حذف پس‌زمینه</h2>
    <video id="video" autoplay playsinline></video>
    <canvas id="canvas"></canvas>
    <script>
        const video = document.getElementById("video");
        const canvas = document.getElementById("canvas");
        const ctx = canvas.getContext("2d");

        // دریافت ویدیو از دوربین
        navigator.mediaDevices.getUserMedia({ video: true })
            .then(stream => {
                video.srcObject = stream;
            })
            .catch(err => console.error("خطا در دریافت ویدیو:", err));

        async function setupPose() {
            const pose = new Pose.Pose({
                locateFile: (file) => `https://cdn.jsdelivr.net/npm/@mediapipe/pose/${file}`
            });

            pose.setOptions({
                modelComplexity: 1,
                smoothLandmarks: true,
                enableSegmentation: true,
                smoothSegmentation: true
            });

            pose.onResults(processResults);

            async function detectPose() {
                await pose.send({ image: video });
                requestAnimationFrame(detectPose);
            }

            await pose.initialize();
            detectPose();
        }

        function processResults(results) {
            canvas.width = video.videoWidth;
            canvas.height = video.videoHeight;
            ctx.clearRect(0, 0, canvas.width, canvas.height);

            if (results.segmentationMask) {
                ctx.drawImage(results.segmentationMask, 0, 0, canvas.width, canvas.height);

                const imageData = ctx.getImageData(0, 0, canvas.width, canvas.height);
                const data = imageData.data;

                for (let i = 0; i < data.length; i += 4) {
                    if (data[i + 3] < 200) { // مقدار شفافیت پس‌زمینه
                        data[i + 3] = 0; // کاملاً شفاف
                    }
                }

                ctx.putImageData(imageData, 0, 0);
            }

            if (results.poseLandmarks) {
                ctx.drawImage(video, 0, 0, canvas.width, canvas.height);

                results.poseLandmarks.forEach((landmark) => {
                    ctx.fillStyle = "red";
                    ctx.beginPath();
                    ctx.arc(landmark.x * canvas.width, landmark.y * canvas.height, 5, 0, 2 * Math.PI);
                    ctx.fill();
                });
            }
        }

        video.addEventListener("loadeddata", setupPose);
    </script>
</body>
</html>
