<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>VR Camera with Face Detection</title>
    <style>
        body {
            margin: 0;
            overflow: hidden;
        }
        .container {
            display: flex;
            width: 100vw;
            height: 100vh;
        }
        .camera-view {
            width: 50%;
            height: 100%;
            position: relative;
            overflow: hidden;
        }
        video {
            width: 100%;
            height: 100%;
            object-fit: cover;
        }
        canvas {
            position: absolute;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
        }
    </style>
</head>
<body>
    <div class="container">
        <div class="camera-view" id="view-left">
            <video id="video-left" autoplay playsinline></video>
            <canvas id="canvas-left"></canvas>
        </div>
        <div class="camera-view" id="view-right">
            <video id="video-right" autoplay playsinline></video>
            <canvas id="canvas-right"></canvas>
        </div>
    </div>

    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs"></script>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/face-detection"></script>
    <script>
        async function setupCamera() {
            const constraints = { video: { facingMode: 'environment' } };
            const stream = await navigator.mediaDevices.getUserMedia(constraints);

            const videoLeft = document.getElementById('video-left');
            const videoRight = document.getElementById('video-right');

            videoLeft.srcObject = stream;
            videoRight.srcObject = stream;

            return { videoLeft, videoRight };
        }

        async function detectFaces(video, canvas) {
            const ctx = canvas.getContext('2d');
            const detector = await faceDetection.createDetector(faceDetection.SupportedModels.MediaPipeFaceMesh);

            function drawFaces() {
                ctx.clearRect(0, 0, canvas.width, canvas.height);
                ctx.strokeStyle = 'green';
                ctx.lineWidth = 2;

                detector.estimateFaces(video).then(faces => {
                    faces.forEach(face => {
                        const box = face.box;
                        ctx.strokeRect(box.xMin, box.yMin, box.width, box.height);
                    });
                });

                requestAnimationFrame(() => drawFaces());
            }

            drawFaces();
        }

        async function main() {
            const { videoLeft, videoRight } = await setupCamera();

            const canvasLeft = document.getElementById('canvas-left');
            const canvasRight = document.getElementById('canvas-right');

            canvasLeft.width = videoLeft.videoWidth / 2;
            canvasLeft.height = videoLeft.videoHeight / 2;
            canvasRight.width = videoRight.videoWidth / 2;
            canvasRight.height = videoRight.videoHeight / 2;

            await detectFaces(videoLeft, canvasLeft);
            await detectFaces(videoRight, canvasRight);
        }

        main();
    </script>
</body>
</html>
